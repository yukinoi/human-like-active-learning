{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "j0Q_mf2PluX2",
    "outputId": "60166cd9-e8fc-44b0-a987-6319729fef69"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PyDuyCJtYjC8"
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "def get_dataset(name):\n",
    "    if name == 'MNIST':\n",
    "        return get_MNIST()\n",
    "    elif name == 'FashionMNIST':\n",
    "        return get_FashionMNIST()\n",
    "    \n",
    "\n",
    "def get_MNIST():\n",
    "    raw_tr = datasets.MNIST('./MNIST', train=True, download=True)\n",
    "    raw_te = datasets.MNIST('./MNIST', train=False, download=True)\n",
    "    X_tr = raw_tr.train_data\n",
    "    Y_tr = raw_tr.train_labels\n",
    "    X_te = raw_te.test_data\n",
    "    Y_te = raw_te.test_labels\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "\n",
    "def get_FashionMNIST():\n",
    "    raw_tr = datasets.FashionMNIST('./FashionMNIST', train=True, download=True)\n",
    "    raw_te = datasets.FashionMNIST('./FashionMNIST', train=False, download=True)\n",
    "    X_tr = raw_tr.train_data\n",
    "    Y_tr = raw_tr.train_labels\n",
    "    X_te = raw_te.test_data\n",
    "    Y_te = raw_te.test_labels\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "\n",
    "def get_handler(name):\n",
    "    if name == 'MNIST':\n",
    "        return DataHandler1\n",
    "    elif name == 'FashionMNIST':\n",
    "        return DataHandler1\n",
    "\n",
    "class DataHandler1(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.X[index], self.Y[index]\n",
    "        if self.transform is not None:\n",
    "            x = Image.fromarray(x.numpy(), mode='L')\n",
    "            x = self.transform(x)\n",
    "        return x, y, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLXZAFd-YL3V"
   },
   "outputs": [],
   "source": [
    "# models\n",
    "def get_net(name):\n",
    "    if (name == 'MNIST') or (name == 'FashionMNIST'):\n",
    "        return Net1\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        e1 = F.relu(self.fc1(x))\n",
    "        x = F.dropout(e1, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x, e1\n",
    "\n",
    "    def get_embedding_dim(self):\n",
    "        return 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4D0IStMlZm3B"
   },
   "outputs": [],
   "source": [
    "# strategies\n",
    "class Strategy:\n",
    "    def __init__(self, X, Y, idxs_lb, net, handler, args):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.idxs_lb = idxs_lb\n",
    "        self.net = net\n",
    "        self.handler = handler\n",
    "        self.args = args\n",
    "        self.n_pool = len(Y)\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    def query(self, n):\n",
    "        pass\n",
    "\n",
    "    def update(self, idxs_lb):\n",
    "        self.idxs_lb = idxs_lb\n",
    "\n",
    "    def _train(self, epoch, loader_tr, optimizer):\n",
    "        self.clf.train()\n",
    "        for batch_idx, (x, y, idxs) in enumerate(loader_tr):\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            out, e1 = self.clf(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    def _train_irt(self, epoch, loader_tr, optimizer, alpha, beta, a,  b):\n",
    "        self.clf.train()\n",
    "        for batch_idx, (x, y, idxs) in enumerate(loader_tr):\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            out, e1 = self.clf(x)\n",
    "            loss = a + (b-a)*F.cross_entropy(alpha*(out-beta), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def train(self):\n",
    "        n_epoch = self.args['n_epoch']\n",
    "        self.clf = self.net().to(self.device)\n",
    "        optimizer = optim.SGD(self.clf.parameters(), **self.args['optimizer_args'])\n",
    "\n",
    "        idxs_train = np.arange(self.n_pool)[self.idxs_lb]\n",
    "        loader_tr = DataLoader(self.handler(self.X[idxs_train], self.Y[idxs_train], transform=self.args['transform']),\n",
    "                            shuffle=True, **self.args['loader_tr_args'])\n",
    "\n",
    "        for epoch in range(1, n_epoch+1):\n",
    "            self._train(epoch, loader_tr, optimizer)\n",
    "            \n",
    "    def train_irt(self, alpha, beta, a,  b):\n",
    "        n_epoch = self.args['n_epoch']\n",
    "        self.clf = self.net().to(self.device)\n",
    "        optimizer = optim.SGD(self.clf.parameters(), **self.args['optimizer_args'])\n",
    "\n",
    "        idxs_train = np.arange(self.n_pool)[self.idxs_lb]\n",
    "        loader_tr = DataLoader(self.handler(self.X[idxs_train], self.Y[idxs_train], transform=self.args['transform']),\n",
    "                            shuffle=True, **self.args['loader_tr_args'])\n",
    "\n",
    "        for epoch in range(1, n_epoch+1):\n",
    "            self._train_irt(epoch, loader_tr, optimizer, alpha, beta, a,  b)\n",
    "\n",
    "    def predict(self, X, Y):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.eval()\n",
    "        P = torch.zeros(len(Y), dtype=Y.dtype)\n",
    "        with torch.no_grad():\n",
    "            for x, y, idxs in loader_te:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out, e1 = self.clf(x)\n",
    "\n",
    "                pred = out.max(1)[1]\n",
    "                P[idxs] = pred.cpu()\n",
    "\n",
    "        return P\n",
    "\n",
    "    def predict_prob(self, X, Y):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.eval()\n",
    "        probs = torch.zeros([len(Y), len(np.unique(Y))])\n",
    "        with torch.no_grad():\n",
    "            for x, y, idxs in loader_te:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out, e1 = self.clf(x)\n",
    "                prob = F.softmax(out, dim=1)\n",
    "                probs[idxs] = prob.cpu()\n",
    "        \n",
    "        return probs\n",
    "\n",
    "    def predict_prob_irt(self, X, Y, alpha, beta, a,  b):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.eval()\n",
    "        probs = torch.zeros([len(Y), len(np.unique(Y))])\n",
    "        with torch.no_grad():\n",
    "            for x, y, idxs in loader_te:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out, e1 = self.clf(x)\n",
    "                prob = a + (b-a)*F.softmax(alpha*(out-beta), dim=1)\n",
    "                probs[idxs] = prob.cpu()\n",
    "        return probs\n",
    "\n",
    "    def get_embedding(self, X, Y):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.eval()\n",
    "        embedding = torch.zeros([len(Y), self.clf.get_embedding_dim()])\n",
    "        with torch.no_grad():\n",
    "            for x, y, idxs in loader_te:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out, e1 = self.clf(x)\n",
    "                embedding[idxs] = e1.cpu()\n",
    "        \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2mo-4K8ZDly"
   },
   "outputs": [],
   "source": [
    "\n",
    "class EntropySampling(Strategy):\n",
    "\tdef __init__(self, X, Y, idxs_lb, net, handler, args):\n",
    "\t\tsuper(EntropySampling, self).__init__(X, Y, idxs_lb, net, handler, args)\n",
    "\n",
    "\tdef query(self, n):\n",
    "\t\tidxs_unlabeled = np.arange(self.n_pool)[~self.idxs_lb]\n",
    "\t\tprobs = self.predict_prob(self.X[idxs_unlabeled], self.Y[idxs_unlabeled])\n",
    "\t\tlog_probs = torch.log(probs)\n",
    "\t\tU = (probs*log_probs).sum(1)\n",
    "\t\treturn idxs_unlabeled[U.sort()[1][:n]]\n",
    "\n",
    "class LeastConfidence(Strategy):\n",
    "\tdef __init__(self, X, Y, idxs_lb, net, handler, args):\n",
    "\t\tsuper(LeastConfidence, self).__init__(X, Y, idxs_lb, net, handler, args)\n",
    "\n",
    "\tdef query(self, n):\n",
    "\t\tidxs_unlabeled = np.arange(self.n_pool)[~self.idxs_lb]\n",
    "\t\tprobs = self.predict_prob(self.X[idxs_unlabeled], self.Y[idxs_unlabeled])\n",
    "\t\tU = probs.max(1)[0]\n",
    "\t\treturn idxs_unlabeled[U.sort()[1][:n]]\n",
    "\n",
    "\n",
    "class InformationCapacity(Strategy):\n",
    "\tdef __init__(self, X, Y, idxs_lb, net, handler, args, alpha=1, beta=0, a=0, b=1):\n",
    "\t\tsuper(InformationCapacity, self).__init__(X, Y, idxs_lb, net, handler, args)\n",
    "\t\tself.alpha = alpha\n",
    "\t\tself.beta = beta\n",
    "\t\tself.a = a\n",
    "\t\tself.b = b\n",
    "\n",
    "\tdef query(self, n):\n",
    "\t\tidxs_unlabeled = np.arange(self.n_pool)[~self.idxs_lb]\n",
    "\t\tprobs = self.predict_prob_irt(self.X[idxs_unlabeled], self.Y[idxs_unlabeled], self.alpha, self.beta, self.a, self.b)\n",
    "\t\ttemp1 = (probs-self.a)*self.alpha\n",
    "\t\ttemp2 = (1-probs)*(self.b-self.a)\n",
    "\t\ttemp3 = (probs-self.a)*(1-self.b) \n",
    "\t\ttemp4 = (self.b-self.a)*(1-self.a)\n",
    "\t\td_probs = temp1*(temp2-temp3)/temp4\n",
    "\t\tJ = d_probs**2/(probs*(1-probs))         \n",
    "\t\tU = J.max(1)[0]\n",
    "\t\treturn idxs_unlabeled[U.sort()[1][:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T12tvAMrpb4r"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(strategy_name, NUM_RUN, alpha, beta, a, b):\n",
    "    res_to_df0 = []\n",
    "    \n",
    "    # print info\n",
    "    print(DATA_NAME)\n",
    "    print('SEED {}'.format(SEED))\n",
    "\n",
    "    for run_ in range(1, NUM_RUN+1):\n",
    "        print('RUN {}'.format(run_))\n",
    "\n",
    "        # generate initial labeled pool\n",
    "        idxs_lb = np.zeros(n_pool, dtype=bool)\n",
    "        idxs_tmp = np.arange(n_pool)\n",
    "        np.random.shuffle(idxs_tmp)\n",
    "        idxs_lb[idxs_tmp[:NUM_INIT_LB]] = True\n",
    "        \n",
    "\n",
    "        if strategy_name == 'EntropySampling':\n",
    "            strategy = EntropySampling(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "        elif strategy_name == 'LeastConfidence':\n",
    "            strategy = LeastConfidence(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "        elif strategy_name == 'InformationCapacity':\n",
    "            strategy = InformationCapacity(X_tr, Y_tr, idxs_lb, net, handler, args, alpha, beta, a, b)\n",
    "\n",
    "        print(type(strategy).__name__)\n",
    "        # round 0 accuracy\n",
    "             \n",
    "        strategy.train()\n",
    "        P = strategy.predict(X_te, Y_te)\n",
    "        acc = np.zeros(NUM_ROUND+1)\n",
    "        acc[0] = 1.0 * (Y_te==P).sum().item() / len(Y_te)\n",
    "        print('Round 0\\ntesting accuracy {}'.format(acc[0]))\n",
    "\n",
    "        res_to_l = []\n",
    "        for rd in range(1, NUM_ROUND+1):\n",
    "            print('Round {}'.format(rd))\n",
    "\n",
    "          # query\n",
    "            q_idxs = strategy.query(NUM_QUERY)\n",
    "            idxs_lb[q_idxs] = True\n",
    "\n",
    "          # update\n",
    "            strategy.update(idxs_lb)\n",
    "            \n",
    "            strategy.train()\n",
    "\n",
    "          # round accuracy\n",
    "            P = strategy.predict(X_te, Y_te)\n",
    "            acc[rd] = 1.0 * (Y_te==P).sum().item() / len(Y_te)\n",
    "            print('testing accuracy {}'.format(acc[rd]))\n",
    "            res_to_l.append(acc[rd]) \n",
    "        df = pd.DataFrame(res_to_l, columns=[type(strategy).__name__ + '_run_' + str(run_)])\n",
    "        res_to_df0.append(df)\n",
    "\n",
    "    print(acc)\n",
    "    res_to_df0 = pd.concat(res_to_df0, axis=1)\n",
    "    pd.DataFrame.from_dict(res_to_df0).to_csv(type(strategy).__name__ + '_' + DATA_NAME + '_rnd_' + str(NUM_ROUND) + '_run_' + str(NUM_RUN) + '_lb_' +str(NUM_INIT_LB) + '.csv', index=False)\n",
    "\n",
    "    return res_to_df0, type(strategy).__name__\n",
    "\n",
    "\n",
    "# plots\n",
    "def plot_round(ax, strategy, num_run, num_round, NUM_INIT_LB, DATA_NAME, minx, maxx, miny, maxy, color, color_back, linestyle, label):\n",
    "    df = pd.read_csv(strategy + '_' + DATA_NAME + '_rnd_' + str(NUM_ROUND) + '_run_' + str(NUM_RUN) + '_lb_' +str(NUM_INIT_LB) + '.csv')\n",
    "    df_mean = df.mean(axis = 1)\n",
    "    df_std = df.std(axis = 1)\n",
    "    \n",
    "    x_axis = np.linspace(1, num_round, num_round)\n",
    "    ax.plot(x_axis, df_mean, color = color, linestyle=linestyle, linewidth = 1.25, label = label)\n",
    "    ax.fill_between(x_axis, df_mean + df_std, df_mean-df_std, edgecolor=color, facecolor=color_back, where = True, interpolate = True, alpha = 0.3)    \n",
    "\n",
    "    ax.legend(loc = 'lower right', prop={'size': 16})\n",
    "    ax.grid()\n",
    "    ax.set_xlim([minx, maxx])\n",
    "    ax.set_ylim([miny, maxy])\n",
    "    \n",
    "    ax.set_xlabel('round', size=16)\n",
    "    ax.set_ylabel('accuracy', size=16)\n",
    "    \n",
    "    # Turn on the minor TICKS, which are required for the minor GRID\n",
    "    ax.minorticks_on()\n",
    "\n",
    "    # Customize the major grid\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.25', color='k')\n",
    "    # Customize the minor grid\n",
    "    #ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "\n",
    "  \n",
    "    ax.set_title('The number of labeled pool = '+str(NUM_INIT_LB), size=18)\n",
    "\n",
    "# plots\n",
    "def stats_round(strategy, num_run, num_round, NUM_INIT_LB, DATA_NAME):\n",
    "    df = pd.read_csv(strategy + '_' + DATA_NAME + '_rnd_' + str(NUM_ROUND) + '_run_' + str(NUM_RUN) + '_lb_' +str(NUM_INIT_LB) + '.csv')\n",
    "    df_mean = df.mean(axis = 1)\n",
    "    df_std = df.std(axis = 1)\n",
    "    \n",
    "    res_mean = df_mean.mean()\n",
    "    res_std = df_std.mean()\n",
    "    \n",
    "    return res_mean, res_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "7rfEyIhhnRKw",
    "outputId": "14028918-cb9b-4134-9c92-ce0b209b07ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled pool: 100\n",
      "Number of unlabeled pool: 9900\n",
      "Number of testing pool: 10000\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "SEED = 1\n",
    "\n",
    "NUM_INIT_LB = 100\n",
    "NUM_QUERY = 100\n",
    "NUM_ROUND = 50\n",
    "\n",
    "#DATA_NAME = 'MNIST'\n",
    "DATA_NAME = 'FashionMNIST'\n",
    "\n",
    "\n",
    "args_pool = {'MNIST':\n",
    "                {'n_epoch': 10, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'loader_tr_args':{'batch_size': 64, 'num_workers': 1},\n",
    "                 'loader_te_args':{'batch_size': 1000, 'num_workers': 1},\n",
    "                 'optimizer_args':{'lr': 0.01, 'momentum': 0.5}},\n",
    "            'FashionMNIST':\n",
    "                {'n_epoch': 10, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'loader_tr_args':{'batch_size': 64, 'num_workers': 1},\n",
    "                 'loader_te_args':{'batch_size': 1000, 'num_workers': 1},\n",
    "                 'optimizer_args':{'lr': 0.01, 'momentum': 0.5}}\n",
    "            }\n",
    "\n",
    "args = args_pool[DATA_NAME]\n",
    "\n",
    "# set seed\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# load dataset\n",
    "X_tr_, Y_tr_, X_te, Y_te = get_dataset(DATA_NAME)\n",
    "X_tr = X_tr_[:10000]\n",
    "Y_tr = Y_tr_[:10000]\n",
    "\n",
    "# start experiment\n",
    "n_pool = len(Y_tr)\n",
    "n_test = len(Y_te)\n",
    "print('Number of labeled pool: {}'.format(NUM_INIT_LB))\n",
    "print('Number of unlabeled pool: {}'.format(n_pool - NUM_INIT_LB))\n",
    "print('Number of testing pool: {}'.format(n_test))\n",
    "\n",
    "# load network\n",
    "net = get_net(DATA_NAME)\n",
    "handler = get_handler(DATA_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiments (.csv files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RUN = 1\n",
    "strategy = 'InformationCapacity'\n",
    "\n",
    "alpha = 0.25\n",
    "beta = 4\n",
    "a = 0.1\n",
    "b = 0.9\n",
    "\n",
    "res_to_df0, strategy = run_experiment(strategy, NUM_RUN, alpha, beta, a, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots (quantitative results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy1 = 'InformationCapacity'\n",
    "strategy2 = 'EntropySampling'\n",
    "strategy3 = 'LeastConfidence'\n",
    "\n",
    "\n",
    "DATA_NAME = 'MNIST'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=[20,6], squeeze=False)\n",
    "matplotlib.rc('xtick', labelsize=14)     \n",
    "matplotlib.rc('ytick', labelsize=14)\n",
    "\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "\n",
    "minx = 1\n",
    "maxx = NUM_ROUND\n",
    "miny1 = 0.05\n",
    "miny2 = 0.3\n",
    "miny3 = 0.65\n",
    "maxy = 1.0\n",
    "NUM_RUN = 10\n",
    "NUM_INIT_LB1 = 100\n",
    "NUM_INIT_LB2 = 500\n",
    "NUM_INIT_LB3 = 1000\n",
    "\n",
    "plot_round(axes[0][0], strategy1, NUM_RUN, NUM_ROUND, NUM_INIT_LB1, DATA_NAME, minx, maxx, miny1, maxy, '#e41a1c', '#fbb4ae', '-', 'Information capacity')\n",
    "plot_round(axes[0][0], strategy2, NUM_RUN, NUM_ROUND, NUM_INIT_LB1, DATA_NAME, minx, maxx, miny1, maxy, '#008837', '#a6dba0', ':', 'Entropy sampling')\n",
    "plot_round(axes[0][0], strategy3, NUM_RUN, NUM_ROUND, NUM_INIT_LB1, DATA_NAME, minx, maxx, miny1, maxy, '#377eb8', '#b3cde3', ':', 'Least Confidence')\n",
    "\n",
    "plot_round(axes[0][1], strategy1, NUM_RUN, NUM_ROUND, NUM_INIT_LB2, DATA_NAME, minx, maxx, miny2, maxy, '#e41a1c', '#fbb4ae', '-', 'Information capacity')\n",
    "plot_round(axes[0][1], strategy2, NUM_RUN, NUM_ROUND, NUM_INIT_LB2, DATA_NAME, minx, maxx, miny2, maxy, '#008837', '#a6dba0', ':', 'Entropy sampling')\n",
    "plot_round(axes[0][1], strategy3, NUM_RUN, NUM_ROUND, NUM_INIT_LB2, DATA_NAME, minx, maxx, miny2, maxy, '#377eb8', '#b3cde3', ':', 'Least Confidence')\n",
    "\n",
    "plot_round(axes[0][2], strategy1, NUM_RUN, NUM_ROUND, NUM_INIT_LB3, DATA_NAME, minx, maxx, miny3, maxy, '#e41a1c', '#fbb4ae', '-', 'Information capacity')\n",
    "plot_round(axes[0][2], strategy2, NUM_RUN, NUM_ROUND, NUM_INIT_LB3, DATA_NAME, minx, maxx, miny3, maxy, '#008837', '#a6dba0', ':', 'Entropy sampling')\n",
    "plot_round(axes[0][2], strategy3, NUM_RUN, NUM_ROUND, NUM_INIT_LB3, DATA_NAME, minx, maxx, miny3, maxy, '#377eb8', '#b3cde3', ':', 'Least Confidence')\n",
    "\n",
    "axes[0][0].text(-0.1, 0.98, '(a)', size=16, horizontalalignment='right', verticalalignment='bottom', transform=axes[0][0].transAxes, )\n",
    "axes[0][1].text(-0.1, 0.98, '(b)', size=16, horizontalalignment='right', verticalalignment='bottom', transform=axes[0][1].transAxes, )\n",
    "axes[0][2].text(-0.1, 0.98, '(c)', size=16, horizontalalignment='right', verticalalignment='bottom', transform=axes[0][2].transAxes, )\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#fig.savefig(DATA_NAME + '_result.pdf', format='pdf', dpi=1000, bbox_inches='tight')\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy1 = 'InformationCapacity'\n",
    "strategy2 = 'EntropySampling'\n",
    "strategy3 = 'LeastConfidence'\n",
    "\n",
    "DATA_NAME = 'FashionMNIST'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=[20,6], squeeze=False)\n",
    "matplotlib.rc('xtick', labelsize=14)     \n",
    "matplotlib.rc('ytick', labelsize=14)\n",
    "\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "\n",
    "minx = 1\n",
    "maxx = NUM_ROUND\n",
    "miny1 = 0.05\n",
    "miny2 = 0.25\n",
    "miny3 = 0.5\n",
    "maxy = 0.8\n",
    "NUM_RUN = 10\n",
    "NUM_INIT_LB1 = 100\n",
    "NUM_INIT_LB2 = 500\n",
    "NUM_INIT_LB3 = 1000\n",
    "\n",
    "plot_round(axes[0][0], strategy1, NUM_RUN, NUM_ROUND, NUM_INIT_LB1, DATA_NAME, minx, maxx, miny1, maxy, '#e41a1c', '#fbb4ae', '-', 'Information capacity')\n",
    "plot_round(axes[0][0], strategy2, NUM_RUN, NUM_ROUND, NUM_INIT_LB1, DATA_NAME, minx, maxx, miny1, maxy, '#008837', '#a6dba0', ':', 'Entropy sampling')\n",
    "plot_round(axes[0][0], strategy3, NUM_RUN, NUM_ROUND, NUM_INIT_LB1, DATA_NAME, minx, maxx, miny1, maxy, '#377eb8', '#b3cde3', ':', 'Least Confidence')\n",
    "\n",
    "plot_round(axes[0][1], strategy1, NUM_RUN, NUM_ROUND, NUM_INIT_LB2, DATA_NAME, minx, maxx, miny2, maxy, '#e41a1c', '#fbb4ae', '-', 'Information capacity')\n",
    "plot_round(axes[0][1], strategy2, NUM_RUN, NUM_ROUND, NUM_INIT_LB2, DATA_NAME, minx, maxx, miny2, maxy, '#008837', '#a6dba0', ':', 'Entropy sampling')\n",
    "plot_round(axes[0][1], strategy3, NUM_RUN, NUM_ROUND, NUM_INIT_LB2, DATA_NAME, minx, maxx, miny2, maxy, '#377eb8', '#b3cde3', ':', 'Least Confidence')\n",
    "\n",
    "plot_round(axes[0][2], strategy1, NUM_RUN, NUM_ROUND, NUM_INIT_LB3, DATA_NAME, minx, maxx, miny3, maxy, '#e41a1c', '#fbb4ae', '-', 'Information capacity')\n",
    "plot_round(axes[0][2], strategy2, NUM_RUN, NUM_ROUND, NUM_INIT_LB3, DATA_NAME, minx, maxx, miny3, maxy, '#008837', '#a6dba0', ':', 'Entropy sampling')\n",
    "plot_round(axes[0][2], strategy3, NUM_RUN, NUM_ROUND, NUM_INIT_LB3, DATA_NAME, minx, maxx, miny3, maxy, '#377eb8', '#b3cde3', ':', 'Least Confidence')\n",
    "\n",
    "\n",
    "axes[0][0].text(-0.1, 0.98, '(a)', size=16, horizontalalignment='right', verticalalignment='bottom', transform=axes[0][0].transAxes, )\n",
    "axes[0][1].text(-0.1, 0.98, '(b)', size=16, horizontalalignment='right', verticalalignment='bottom', transform=axes[0][1].transAxes, )\n",
    "axes[0][2].text(-0.1, 0.98, '(c)', size=16, horizontalalignment='right', verticalalignment='bottom', transform=axes[0][2].transAxes, )\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#fig.savefig(DATA_NAME + '_result.pdf', format='pdf', dpi=1000, bbox_inches='tight')\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy values over rounds (quantitative results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Capacity:\n",
      "0.9152993999999999 0.011759046712358476\n",
      "Entropy Sampling:\n",
      "0.9133281999999998 0.014076564919604784\n",
      "Least Confidence:\n",
      "0.9156454 0.012552382318871598\n"
     ]
    }
   ],
   "source": [
    "NUM_INIT_LB = 1000\n",
    "NUM_ROUND = 50\n",
    "NUM_RUN = 10\n",
    "\n",
    "strategy1 = 'InformationCapacity'\n",
    "strategy2 = 'EntropySampling'\n",
    "strategy3 = 'LeastConfidence'\n",
    "\n",
    "\n",
    "DATA_NAME = 'MNIST'\n",
    "\n",
    "# Information Capacity\n",
    "res_mean, res_std = stats_round(strategy1, NUM_RUN, NUM_ROUND, NUM_INIT_LB, DATA_NAME)\n",
    "df_IC_mean = res_mean\n",
    "df_IC_std = res_std\n",
    "print(\"Information Capacity:\")\n",
    "print(res_mean, res_std)\n",
    "\n",
    "# Entropy Sampling\n",
    "res_mean, res_std = stats_round(strategy2, NUM_RUN, NUM_ROUND, NUM_INIT_LB, DATA_NAME)\n",
    "df_ES_mean = res_mean\n",
    "df_ES_std = res_std\n",
    "print(\"Entropy Sampling:\")\n",
    "print(res_mean, res_std)\n",
    "\n",
    "# Least Confidence\n",
    "res_mean, res_std = stats_round(strategy3, NUM_RUN, NUM_ROUND, NUM_INIT_LB, DATA_NAME)\n",
    "df_LC_mean = res_mean\n",
    "df_LC_std = res_std\n",
    "print(\"Least Confidence:\")\n",
    "print(res_mean, res_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test statistics (quantitative results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYkTrZxkeB66"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "NUM_INIT_LB = 100\n",
    "NUM_ROUND = 50\n",
    "NUM_RUN = 10\n",
    "\n",
    "strategy1 = 'InformationCapacity'\n",
    "strategy2 = 'EntropySampling'\n",
    "strategy3 = 'LeastConfidence'\n",
    "\n",
    "\n",
    "DATA_NAME = 'MNIST'\n",
    "\n",
    "df1 = pd.read_csv(strategy1 + '_' + DATA_NAME + '_rnd_' + str(NUM_ROUND) + '_run_' + str(NUM_RUN) + '_lb_' +str(NUM_INIT_LB) + '.csv')\n",
    "df2 = pd.read_csv(strategy2 + '_' + DATA_NAME + '_rnd_' + str(NUM_ROUND) + '_run_' + str(NUM_RUN) + '_lb_' +str(NUM_INIT_LB) + '.csv')\n",
    "df3 = pd.read_csv(strategy3 + '_' + DATA_NAME + '_rnd_' + str(NUM_ROUND) + '_run_' + str(NUM_RUN) + '_lb_' +str(NUM_INIT_LB) + '.csv')\n",
    "\n",
    "\n",
    "\n",
    "df1_mean = df1.mean(axis = 1)\n",
    "df2_mean = df2.mean(axis = 1)\n",
    "df3_mean = df3.mean(axis = 1)\n",
    "df1_std = df1.std(axis = 1)\n",
    "df2_std = df2.std(axis = 1)\n",
    "df3_std = df3.std(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942.0, 0.9983814874703646)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative options: less or greater\n",
    "\n",
    "w, p = wilcoxon(df1_mean, df2_mean, alternative='less', correction=True)\n",
    "w, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "AL_from_files.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
